{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging using Hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom defaultdict implementation\n",
    "class MyDefaultDict(dict):\n",
    "    def __init__(self, default_factory, *args, **kwargs):\n",
    "        self.default_factory = default_factory\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        else:\n",
    "            self[key] = self.default_factory()\n",
    "            return self[key]\n",
    "\n",
    "# Read training\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Preprocess data\n",
    "train_sentences = train_data['untagged_sentence'].tolist()\n",
    "train_tags = train_data['tagged_sentence'].tolist()\n",
    "\n",
    "\n",
    "def formating(tagged_sentence):\n",
    "    tagged_words = eval(tagged_sentence)\n",
    "    words = [word for word, tag in tagged_words]\n",
    "    tags = [tag for word, tag in tagged_words]\n",
    "    formating_format = list(zip(words, tags))\n",
    "    return formating_format\n",
    "\n",
    "\n",
    "formating_train_tags = [formating(tagged_sentence) for tagged_sentence in train_tags]\n",
    "\n",
    "\n",
    "train_set = formating_train_tags\n",
    "\n",
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "\n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "\n",
    "Vocab = set(tokens)\n",
    "\n",
    "Tg = set([pair[1] for pair in train_tagged_words])\n",
    "\n",
    "# Precompute tag pair counts\n",
    "tag_pair_counts = MyDefaultDict(int)\n",
    "for i in range(len(train_tagged_words) - 1):\n",
    "    current_tag = train_tagged_words[i][1]\n",
    "    next_tag = train_tagged_words[i + 1][1]\n",
    "    tag_pair_counts[(current_tag, next_tag)] += 1\n",
    "\n",
    "# Computing transition matrix using precomputed counts\n",
    "tags_matrix = np.zeros((len(Tg), len(Tg)), dtype='float32')\n",
    "for i, t1 in enumerate(list(Tg)):\n",
    "    for j, t2 in enumerate(list(Tg)):\n",
    "        m = tag_pair_counts[(t1, t2)]\n",
    "        n = sum(tag_pair_counts.get((t1, _t2), 0) for _t2 in Tg)\n",
    "        tags_matrix[i, j] = m / n\n",
    "\n",
    "# Convert the matrix to a DataFrame\n",
    "tags_df = pd.DataFrame(tags_matrix, columns=list(Tg), index=list(Tg))\n",
    "\n",
    "# Precompute tag counts and word given tag counts\n",
    "tag_counts = MyDefaultDict(int)\n",
    "word_tag_counts = MyDefaultDict(lambda: MyDefaultDict(int))\n",
    "\n",
    "for word, tag in train_tagged_words:\n",
    "    tag_counts[tag] += 1\n",
    "    word_tag_counts[word][tag] += 1\n",
    "\n",
    "# Emission Probability Calculation\n",
    "def word_given_tag(word, tag):\n",
    "    return word_tag_counts[word][tag] / tag_counts[tag] if tag_counts[tag] != 0 else 0\n",
    "\n",
    "# Viterbi\n",
    "def HMM_Viterbi(words, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    Tg = list(tag_counts.keys())\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        for tag in Tg:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            emission_p = word_given_tag(word, tag)\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        state_max = Tg[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [01:51, 35.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data\n",
    "test_df = pd.read_csv('test_small.csv')\n",
    "\n",
    "# Initialize a list to store tagged sentences\n",
    "tagged_sentences = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    \n",
    "    untagged_sentence = ast.literal_eval(row['untagged_sentence'])\n",
    "    sentence_id = row['id']\n",
    "    \n",
    "    tagged_sentence = HMM_Viterbi(untagged_sentence)\n",
    "    \n",
    "    tagged_sentences.append({'id': sentence_id, 'tagged_sentence': tagged_sentence})\n",
    "\n",
    "tagged_df = pd.DataFrame(tagged_sentences)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "tagged_df.to_csv('sample_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
